{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAlrBUOd9oQb",
        "outputId": "df59fbba-9cec-44bd-e147-d8caa58c2d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun  6 11:20:05 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzZa3ASaoNfS",
        "outputId": "22f3e975-dd77-4ad0-cf75-776228abd734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAKfxlZPXNTJ",
        "outputId": "08741257-625f-4aa4-f08d-70d03c46b3f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Vz9iYLXTE7",
        "outputId": "ab65efce-63fc-4fb5-aa0d-7b40e80fdb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpriegoths\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JObGU0YoW3EV",
        "outputId": "bdfa49a8-ef39-4bc4-88b3-a4c0e00dce08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUassert: the provided PTX was compiled with an unsupported toolchain. /tmp/tmpriegoths/f5e08d5c-e918-4026-ad05-f3c8449706a8/single_file.cu 61\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <chrono>\n",
        "#include <iostream>\n",
        "\n",
        "#define X 0.1\n",
        "#define Y 7.1\n",
        "#define a 3.0\n",
        "#define N 3\n",
        "\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "\n",
        "__global__ void daxpy(double* vecX,double* vecY,double* vecZ){\n",
        "\n",
        "\tint i = threadIdx.x;\n",
        "\tvecZ[i] = a*vecX[i] + vecY[i];\n",
        "\n",
        "}\n",
        "\n",
        "// everything is written in the main function\n",
        "// in order to maintain an overview over the OpenMP implementation\n",
        "int main(){\n",
        "\n",
        "\t// allocate memory for the host vectors and fill them\n",
        "\tdouble* h_vecX = new double[N];\n",
        "\tdouble* h_vecY = new double[N];\n",
        "\tdouble* h_vecZ = new double[N];\n",
        "\n",
        "\tfor(int i=0;i<N;i++){\n",
        "\t\th_vecX[i] = X;\n",
        "\t\th_vecY[i] = Y;\n",
        "\t}\n",
        "\n",
        "\t// timer variables\n",
        "\tdouble dt_cuda;\n",
        "\tstd::chrono::time_point<std::chrono::system_clock> start;\n",
        "\tstd::chrono::time_point<std::chrono::system_clock> end;\n",
        "\n",
        "\tstart = std::chrono::system_clock::now();\n",
        "\t// allocate the device vectors\n",
        "\tdouble* d_vecX;\n",
        "\tcudaMalloc(&d_vecX,N*sizeof(double));\n",
        "\tdouble* d_vecY;\n",
        "\tcudaMalloc(&d_vecY,N*sizeof(double));\n",
        "\tdouble* d_vecZ;\n",
        "\tcudaMalloc(&d_vecZ,N*sizeof(double));\n",
        "\n",
        "\tcudaMemcpy(d_vecX,h_vecX,N*sizeof(double),cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_vecY,h_vecY,N*sizeof(double),cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_vecZ,h_vecZ,N*sizeof(double),cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdaxpy<<<1,N>>>(d_vecX,d_vecY,d_vecZ);\n",
        "\n",
        "  gpuErrchk( cudaPeekAtLastError() );\n",
        "\n",
        "  for(int i=0;i<N;i++){\n",
        "\t\th_vecX[i] = 0.0;\n",
        "\t}\n",
        "\n",
        "\tcudaMemcpy(h_vecZ,d_vecZ,N*sizeof(double),cudaMemcpyDeviceToHost);\n",
        "  cudaMemcpy(h_vecX,d_vecX,N*sizeof(double),cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tend = std::chrono::system_clock::now();\n",
        "\n",
        "\tdt_cuda = std::chrono::duration_cast<std::chrono::nanoseconds>(end - start).count();\n",
        "\n",
        "\tcudaFree(d_vecX);\n",
        "\tcudaFree(d_vecY);\n",
        "\tcudaFree(d_vecZ);\n",
        "\n",
        "\t// print the outcome\n",
        "\tstd::cout << \"daxpy vector sum with CUDA\" << std::endl;\n",
        "\tstd::cout << \"vectors of size \" << N << std::endl;\n",
        "\tstd::cout << \"CUDA runtime is: \" << dt_cuda << \" ns\" << std::endl;\n",
        "\tstd::cout << \"final result of the sum is: \" << h_vecX[0] << std::endl;\n",
        "\n",
        "\t// free the global memory\n",
        "\tdelete[] h_vecX;\n",
        "\tdelete[] h_vecY;\n",
        "\tdelete[] h_vecZ;\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ]
    }
  ]
}